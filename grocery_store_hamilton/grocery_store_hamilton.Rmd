---
title: Food Deserts or Food Oases? Predicting Grocery Store Locations in Hamilton, Ontario
author:
  - name: Zehui Yin
    email: yinz39@mcmaster.ca
    affiliation: sees
    correspondingauthor: true
address:
  - code: sees
    organization: School of Earth, Environment & Society, McMaster University
    addressline: 1280 Main Street West
    city: Hamilton
    state: Ontario
    postcode: L8S 4K1
    country: Canada
abstract: |
  This is the abstract.

  It consists of two paragraphs.
keywords: 
  - Grocery Store
  - Hamilton
journal: "GEOG 712 Reproducible Research Workflow with GitHub and R"
date: "`r Sys.Date()`"
linenumbers: false
numbersections: true
bibliography: mybibfile.bib
biblio-style: elsarticle-harv # author year style for natbib - use 'elsarticle-num' or 'elsarticle-num-names' for numbered scheme
classoption: preprint, 3p, authoryear # remove authoryear is not using `elsarticle-harv`
# Use a CSL with `citation_package = "default"`
# csl: https://www.zotero.org/styles/elsevier-harvard
output: 
  rticles::elsevier_article:
    keep_tex: true
    citation_package: natbib
---

```{r, echo=FALSE}
# no code chunk echo or message
knitr::opts_chunk$set(
  echo = F,
  message = F
)
```

```{r}
# load packages
library(sf)
library(tidyverse)
library(geog712package)
library(pscl)
library(units)
library(texreg)
library(mapview)
library(tidytransit)
```

```{r}
# read data
data("grocery_DA")

# reproject the data
grocery_DA <- st_transform(grocery_DA, crs = 26917)


# create a point for hamilton downtown
hamilton_downtown <- st_as_sf(data.frame(list("name"="hamilton downtown", 
                                              "x"=43.258657062558896, 
                                              "y"=-79.8707987387457)),
                              crs = 4326, coords = c("y", "x"))
hamilton_downtown <- st_transform(hamilton_downtown, crs = 26917)

# read hsr GTFS
hsr <- read_gtfs("https://github.com/zehuiyin/geog712package/raw/refs/heads/main/data-raw/fall2024_GTFS_static.zip")

# convert to hsr stops
hsr_stops <- st_as_sf(hsr$stops,
                      coords = c("stop_lon", "stop_lat"),
                      crs = 4326)
hsr_stops <- st_transform(hsr_stops, crs = 26917)
```

```{r, warning=FALSE}
# compute the number of hsr stops in each DA
stops_inter <- st_intersection(hsr_stops, grocery_DA)

stop_count <- stops_inter |> st_drop_geometry() |> group_by(GeoUID) |> count()

colnames(stop_count) <- c("GeoUID", "n_hsr_stops")

grocery_DA <- merge(x = grocery_DA, 
                    y = stop_count,
                    by = "GeoUID",
                    all.x = TRUE
                    )

grocery_DA[is.na(grocery_DA$n_hsr_stops),]$n_hsr_stops <- 0

# convert it into a factor
hsr_level <- cut(grocery_DA$n_hsr_stops,
                 breaks = c(-1, quantile(grocery_DA$n_hsr_stops)[3:5]))

levels(hsr_level) <- c("low" , "mid", "high")

grocery_DA$hsr_level <- hsr_level
```

```{r, warning=FALSE}
# construct some independent variables

# population density
grocery_DA$pop_density <- grocery_DA$v_CA21_1..Population..2021/grocery_DA$v_CA21_7..Land.area.in.square.kilometres
grocery_DA$log_pop_density <- log(grocery_DA$pop_density + 1)

# log land area
grocery_DA$log_area <- log(grocery_DA$v_CA21_7..Land.area.in.square.kilometres)

# calculate distance to downtown
grocery_DA$dist_to_downtown <- st_distance(st_centroid(grocery_DA), 
                                           hamilton_downtown) |> drop_units()
grocery_DA$log_dist_to_downtown <- log(grocery_DA$dist_to_downtown)

# percentage of people age from 0 - 24
grocery_DA$PCT_aged_under_24 <- (grocery_DA$v_CA21_11..0.to.14.years + 
                                   grocery_DA$v_CA21_89..20.to.24.years)/
  grocery_DA$v_CA21_8..Total...Age*100

# percentage of people aged above 65
grocery_DA$PCT_aged_above_65 <- grocery_DA$v_CA21_251..65.years.and.over/
  grocery_DA$v_CA21_8..Total...Age*100

# percentage of people living in single detached house
grocery_DA$PCT_single_detached <- grocery_DA$v_CA21_435..Single.detached.house/
  grocery_DA$v_CA21_434..Occupied.private.dwellings.by.structural.type.of.dwelling.data*100

# percentage of people married or living common-law
grocery_DA$PCT_married_common_law <- grocery_DA$v_CA21_456..Married.or.living.common.law/
  grocery_DA$v_CA21_453..Marital.status.for.the.total.population.aged.15.years.and.over*100

# percentage of people with income less than 40k
grocery_DA$PCT_income_less_40k <- (grocery_DA$v_CA21_674..Under..10.000..including.loss. + 
                                     grocery_DA$v_CA21_677...10.000.to..19.999 + 
                                     grocery_DA$v_CA21_680...20.000.to..29.999 + 
                                     grocery_DA$v_CA21_683...30.000.to..39.999)/
  grocery_DA$v_CA21_671..With.total.income*100

# percentage of people with income greater than 100k
grocery_DA$PCT_income_greater_100k <- (grocery_DA$v_CA21_707...100.000.to..149.999 + 
                                         grocery_DA$v_CA21_710...150.000.and.over)/
  grocery_DA$v_CA21_671..With.total.income*100

# percentage of population with no knowledge of official language
grocery_DA$PCT_dont_know_official_language <- grocery_DA$v_CA21_1156..Neither.English.nor.French/
  grocery_DA$v_CA21_1144..Knowledge.of.official.languages.for.the.total.population.excluding.institutional.residents*100

# percentage of population who don't speak official language at home
grocery_DA$PCT_not_speak_offcial_language_at_home <- grocery_DA$v_CA21_2176..Non.official.language/
  grocery_DA$v_CA21_2167..All.languages.spoken.at.home.for.the.total.population.excluding.institutional.residents*100
```

```{r}
# construct a contiguity matrix
dist_m <- st_distance(grocery_DA)
dist_m <- drop_units(dist_m)
dist_m[dist_m == 0] <- -999
dist_m[dist_m != -999] <- 0
dist_m[dist_m == -999] <- 1
diag(dist_m) <- 0
```

```{r}
# compute spatial lags
# total number of grocery stores in neighbour CT
grocery_DA$Freq_sum_lag <- dist_m %*% grocery_DA$Freq

# total number of neighbour CT
grocery_DA$n_neighbour <- apply(dist_m, 1, sum)

# row normalize
grocery_DA$Freq_lag <- grocery_DA$Freq_sum_lag/grocery_DA$n_neighbour
```

```{r, results='hide'}
# fit a zero inflated negative binomial regression
m1 <- zeroinfl(Freq ~ Freq_lag + 
                 PCT_aged_under_24 + 
                 PCT_aged_above_65 +
                 PCT_dont_know_official_language +
                 PCT_not_speak_offcial_language_at_home +
                 PCT_single_detached +
                 PCT_income_less_40k +
                 PCT_income_greater_100k + 
                 PCT_married_common_law + 
                 log_dist_to_downtown +
                 log_pop_density |
                 log_pop_density +
                 PCT_not_speak_offcial_language_at_home + 
                 PCT_married_common_law +
                 hsr_level +
                 log_area +
                 Freq_lag,
               data = grocery_DA, dist = "negbin")

summary(m1)
```

```{r, results='asis'}
# render output
texreg(m1,
       caption = "\\label{tab66}Regression results",
       custom.model.names = c("Zero inflated negative binomial model"),
       fontsize = "footnotesize",
       stars = c(0.001, 0.01, 0.05, 0.1),
       custom.coef.map = list(
         # Count model
         "Count model: Freq_lag" = "Count model: Spatial lag of grocery store count",
         "Count model: PCT_aged_under_24" = "Count model: Percentage of population aged below 24 years old",
         "Count model: PCT_aged_above_65" = "Count model: Percentage of population aged above 65 years old",
         "Count model: PCT_dont_know_official_language" = "Count model: Percentage of population don't know official language",
         "Count model: PCT_not_speak_offcial_language_at_home" = "Count model: Percentage of population don't speak official language at home",
         "Count model: PCT_single_detached" = "Count model: Percentage of population live in single detached houses",
         "Count model: PCT_income_less_40k" = "Count model: Percentage of population have annual total income less than 40K",
         "Count model: PCT_income_greater_100k" = "Count model: Percentage of population have annual total income more than 100K",
         "Count model: PCT_married_common_law" = "Count model: Percentage of population that are married or live in common-law",
         "Count model: log_pop_density" = "Count model: Natural log of (population density + 1)",
         "Count model: log_dist_to_downtown" = "Count model: Natural log of distance from DA centroid to Hamilton downtown",
         "Count model: hsr_levelmid" = "Count model: Number of HSR bus stops (50-75 percentile)",
         "Count model: hsr_levelhigh" = "Count model: Number of HSR bus stops (75-100 percentile)",
         "Count model: log_area" = "Count model: Natural log of area size in square kilometres",
         # Zero model
         "Zero model: Freq_lag" = "Zero model: Spatial lag of grocery store count",
         "Zero model: PCT_aged_under_24" = "Zero model: Percentage of population aged below 24 years old",
         "Zero model: PCT_aged_above_65" = "Zero model: Percentage of population aged above 65 years old",
         "Zero model: PCT_dont_know_official_language" = "Zero model: Percentage of population don't know official language",
         "Zero model: PCT_not_speak_offcial_language_at_home" = "Zero model: Percentage of population don't speak official language at home",
         "Zero model: PCT_single_detached" = "Zero model: Percentage of population live in single detached houses",
         "Zero model: PCT_income_less_40k" = "Zero model: Percentage of population have annual total income less than 40K",
         "Zero model: PCT_income_greater_100k" = "Zero model: Percentage of population have annual total income more than 100K",
         "Zero model: PCT_married_common_law" = "Zero model: Percentage of population that are married or live in common-law",
         "Zero model: log_pop_density" = "Zero model: Natural log of (population density + 1)",
         "Zero model: log_dist_to_downtown" = "Zero model: Natural log of distance from DA centroid to Hamilton downtown",
         "Zero model: hsr_levelmid" = "Zero model: Number of HSR bus stops (50-75 percentile)",
         "Zero model: hsr_levelhigh" = "Zero model: Number of HSR bus stops (75-100 percentile)",
         "Zero model: log_area" = "Zero model: Natural log of area size in square kilometres"
        )
       )
```

############################################################
############################################################

Please make sure that your manuscript follows the guidelines in the 
Guide for Authors of the relevant journal. It is not necessary to 
typeset your manuscript in exactly the same way as an article, 
unless you are submitting to a camera-ready copy (CRC) journal.

For detailed instructions regarding the elsevier article class, see   <https://www.elsevier.com/authors/policies-and-guidelines/latex-instructions>

# Bibliography styles

Here are two sample references: @Feynman1963118 [@Dirac1953888].

By default, natbib will be used with the `authoryear` style, set in `classoption` variable in YAML and with `elsearticle-harv.bst` which is among provided style by `elsarticle` documentclass. Other available style are `elsarticle-num.bst` and `elsarticle-num-names.bst` — the first one can be used for the numbered scheme, second one for numbered with new options of natbib.sty. 

You can sets extra options with `natbiboptions` variable in YAML header. Example 
```yaml
natbiboptions: longnamesfirst,angle,semicolon
```

There are various more specific bibliography styles available at
<https://support.stmdocs.in/wiki/index.php?title=Model-wise_bibliographic_style_files>. 
To use one of these, add it in the header using, for example, `biblio-style: model1-num-names`.

## Using CSL 

If `citation_package` is set to `default` in `elsevier_article()`, then pandoc is used for citations instead of `natbib`. In this case, the `csl` option is used to format the references. Alternative `csl` files are available from <https://www.zotero.org/styles?q=elsevier>. These can be downloaded
and stored locally, or the url can be used as in the example header.

# Equations

Here is an equation:
$$ 
  f_{X}(x) = \left(\frac{\alpha}{\beta}\right)
  \left(\frac{x}{\beta}\right)^{\alpha-1}
  e^{-\left(\frac{x}{\beta}\right)^{\alpha}}; 
  \alpha,\beta,x > 0 .
$$

Here is another:
\begin{align}
  a^2+b^2=c^2.
\end{align}

Inline equations: $\sum_{i = 2}^\infty\{\alpha_i^\beta\}$

# Figures and tables

Figure \ref{fig2} is generated using an R chunk.

```{r fig2, fig.width = 5, fig.height = 5, fig.align='center', out.width="50%", fig.cap = "\\label{fig2}A meaningless scatterplot.", echo = FALSE}
plot(runif(25), runif(25))
```

# Tables coming from R

Tables can also be generated using R chunks, as shown in Table \ref{tab1} for example.

```{r tab1, echo = TRUE}
knitr::kable(head(mtcars)[,1:4], 
    caption = "\\label{tab1}Caption centered above table"
)
```

# References {-}

